{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Experiments for the input format : Comma Separated Labels + Row Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "from rdflib import Graph\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "import functions_multiple_tokens_HT as functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing all pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Labels\n",
    "\n",
    "file_path = '../../input/HardTables/HT_train_label_comma.pickle'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    train_labels = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Choices\n",
    "file_path = '../../input/HardTables/HT_train_choices.pickle'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    train_choices = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust Train Choices to the comma separated format\n",
    "train_choices = [[item.split('. ')[1] if '. ' in item else item for item in sublist] for sublist in train_choices]\n",
    "train_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Annotations\n",
    "file_path = '../../input/HardTables/HT_train_vals.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    train_vals = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Rows\n",
    "file_path = '../../input/HardTables/HT_train_rows.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    train_rows = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set rows\n",
    "file_path = '../../input/HardTables/HT_test_rows.pickle'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    test_rows = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing test rows for the annotation process\n",
    "test_rows =[[value for value in sublist if value != ''] for sublist in test_rows]\n",
    "test_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import train files for the contrastive prompt \n",
    "\n",
    "file_path = '../../input/p7/p7_comma_train_choices.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    train_choices_p7_comma = pickle.load(file)\n",
    "\n",
    "\n",
    "file_path = '../../input/p7/p7_mc_train_choices.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    train_choices_p7_mc = pickle.load(file)\n",
    "\n",
    "\n",
    "file_path = '../../input/p7/p7_train_labels.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    train_labels_p7 = pickle.load(file)\n",
    "\n",
    "\n",
    "file_path = '../../input/p7/p7_train_vals.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    train_vals_p7 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entity Lookup Dictionary\n",
    "\n",
    "file_path = '../../input/HardTables/HT_dict_5.pickle'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    final_dict = pickle.load(file)\n",
    "\n",
    "final_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Annotations Chain Of Thought\n",
    "file_path = '../../input/HardTables/train_labels_cot_comma.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    train_labels_cot = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Candidate Entities Separated with Comma\n",
    "entities_text = []\n",
    "\n",
    "for key, value in final_dict.items():\n",
    "    sublist_entity = []\n",
    "    for key2, value2 in value.items():\n",
    "        sublist_entity.append(key2)\n",
    "\n",
    "    \n",
    "    entities_text.append(sublist_entity)\n",
    "\n",
    "entities_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell Values\n",
    "vals = []\n",
    "for key, value in final_dict.items():\n",
    "    vals.append (key[1])\n",
    "\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell table locations\n",
    "\n",
    "locations = []\n",
    "for key, value in final_dict.items():\n",
    "    locations.append (key[0])\n",
    "\n",
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Connecting to OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL SETUP\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values\n",
    "from langchain import PromptTemplate, LLMChain, OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONNECTING WITH OPEN AI\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "# enter your api key\n",
    "OPENAI_API_KEY = getpass(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    openai_api_key='OPENAI_API_KEY',\n",
    "    temperature=0,\n",
    "    model='gpt-3.5-turbo-1106',\n",
    "    #max_tokens=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 1: Zero Shot: No Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "preds_p1 = []\n",
    "messages = []\n",
    "\n",
    "# Execute prompt messages in batches of 2\n",
    "batch_size = 2\n",
    "\n",
    "# Limit the loop to the first 1000 rows\n",
    "num_rows_limit = 1000\n",
    "count = 0\n",
    "\n",
    "\n",
    "for (key, value), test_row, sublist in tqdm(zip(final_dict.items(), test_rows, entities_text), desc=\"Processing items\", total=len(final_dict)):\n",
    "    count += 1\n",
    "    messages.append(SystemMessage(content=f\"Your task is to classify a cell entity in a row by selecting the most appropriate option from the provided list: {', '.join(sublist)} \\n Respond only with the choice \" ))\n",
    "    messages.append(HumanMessage(content=f\"Given the  row: {test_row} \\n  Classify the cell: {key[1]}\" ))\n",
    "\n",
    "    if len(messages) >= batch_size:\n",
    "        #print(messages)\n",
    "        res = chat(messages)\n",
    "        preds_p1.append(res.content)\n",
    "        messages = []\n",
    "\n",
    "    # Check if the limit is reached\n",
    "    if count >= num_rows_limit:\n",
    "        break\n",
    "\n",
    "if messages:\n",
    "    res = chat(messages)\n",
    "    print(res)  \n",
    "    preds_p1.append(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 2: Zero-Shot: With Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "preds_p2 = []\n",
    "messages = []\n",
    "\n",
    "# Execute prompt messages in batches of 3\n",
    "batch_size = 3\n",
    "\n",
    "# Limit the loop to the first 1000 rows\n",
    "num_rows_limit = 1000\n",
    "count = 0\n",
    "\n",
    "for (key, value),test_row, sublist in tqdm(zip(final_dict.items(), test_rows, entities_text), desc=\"Processing items\", total=len(final_dict)):\n",
    "    count += 1\n",
    "    messages.append(SystemMessage(content=f\"Your task is to classify a cell entity in a row by selecting the most appropriate option from the provided list: {', '.join(sublist)} \" ))\n",
    "    messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the choices given above. 2. Examine the values of the row and the given cell. 3. Select only ONE of the classes above, that best represents the meaning of the cell. 4. Respond only with the choice \"))\n",
    "    messages.append(HumanMessage(content=f\"Given the row: {test_row}  \\n Classify the cell: {key[1]}\" ))\n",
    "\n",
    "    if len(messages) >= batch_size:\n",
    "        #print(messages)\n",
    "        res = chat(messages)\n",
    "        preds_p2.append(res.content)\n",
    "        messages = []\n",
    "\n",
    "    # Check if the limit is reached\n",
    "    if count >= num_rows_limit:\n",
    "        break\n",
    "\n",
    "if messages:\n",
    "    res = chat(messages)\n",
    "    print(res)  \n",
    "    preds_p2.append(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 3: Five-Shot with Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "preds_p3 = []\n",
    "messages = []\n",
    "\n",
    "# Execute prompt messages in batches of 13\n",
    "batch_size = 13\n",
    "\n",
    "# Limit the loop to the first 1000 rows\n",
    "num_rows_limit = 1000\n",
    "count = 0\n",
    "\n",
    "for (key, value),test_row, sublist in tqdm(zip(final_dict.items(),test_rows, entities_text), desc=\"Processing items\", total=len(final_dict)):\n",
    "    count += 1\n",
    "    for i in range(0,5):\n",
    "        messages.append(HumanMessage(content=f\"Your task is to annotate a cell entity by selecting the most appropriate option from the provided list: {', '.join(train_choices[i])}. \\n {train_vals[i]}\"))\n",
    "        messages.append(AIMessage(content=f\"{train_labels[i]}\"))\n",
    "    \n",
    "    messages.append(SystemMessage(content=f\"Your task is to classify a cell entity in a row by selecting the most appropriate option from the provided list: {', '.join(sublist)}\" ))\n",
    "    messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the choices given above. 2. Examine the values of the row and the given cell. 3. Select only ONE of the classes above, that best represents the meaning of the cell. 4. Respond only with the choice \"))\n",
    "    messages.append(HumanMessage(content=f\"Given the row: {test_row}  \\n Classify the cell: {key[1]}\" ))\n",
    "\n",
    "\n",
    "    if len(messages) >= batch_size:\n",
    "        #print(messages)\n",
    "        res = chat(messages)\n",
    "        preds_p3.append(res.content)\n",
    "        messages = []\n",
    "\n",
    "    # Check if the limit is reached\n",
    "    if count >= num_rows_limit:\n",
    "        break\n",
    "\n",
    "if messages:\n",
    "    res = chat(messages)\n",
    "    print(res)  \n",
    "    preds_p3.append(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 4: Five-Shot without Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "preds_p4 = []\n",
    "messages = []\n",
    "\n",
    "# Execute prompt messages in batches of 12\n",
    "batch_size = 12\n",
    "\n",
    "# Limit the loop to the first 1000 rows\n",
    "num_rows_limit = 1000\n",
    "count = 0\n",
    "\n",
    "\n",
    "for (key, value),test_row,sublist in tqdm(zip(final_dict.items(),test_rows, entities_text), desc=\"Processing items\", total=len(final_dict)):\n",
    "    count += 1\n",
    "    for i in range(0,5):\n",
    "        messages.append(HumanMessage(content=f\"Your task is to annotate a cell entity by selecting the most appropriate option from the provided list: {', '.join(train_choices[i])}. \\n {train_vals[i]}\"))\n",
    "        messages.append(AIMessage(content=f\"{train_labels[i]}\"))\n",
    "    \n",
    "    messages.append(SystemMessage(content=f\"Your task is to classify a cell entity in a row by selecting the most appropriate option from the provided list: {', '.join(sublist)} \\n Respond only with the choice \" ))\n",
    "    messages.append(HumanMessage(content=f\"Given the row: {test_row}  \\n Classify the cell: {key[1]}\" ))\n",
    "\n",
    "    if len(messages) >= batch_size:\n",
    "        #print(messages)\n",
    "        res = chat(messages)\n",
    "        preds_p4.append(res.content)\n",
    "        messages = []\n",
    "\n",
    "    # Check if the limit is reached\n",
    "    if count >= num_rows_limit:\n",
    "        break\n",
    "\n",
    "if messages:\n",
    "    res = chat(messages)\n",
    "    print(res)  \n",
    "    preds_p4.append(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 5: Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "preds_p5 = []\n",
    "messages = []\n",
    "\n",
    "# Execute prompt messages in batches of 12\n",
    "batch_size = 12\n",
    "\n",
    "# Limit the loop to the first 1000 rows\n",
    "num_rows_limit = 1000\n",
    "count = 0\n",
    "\n",
    "\n",
    "for (key, value),test_row, sublist in tqdm(zip(final_dict.items(),test_rows, entities_text), desc=\"Processing items\", total=len(final_dict)):\n",
    "    count += 1\n",
    "    for i in range(0,5):\n",
    "        messages.append(HumanMessage(content=f\"Your task is to classify a cell entity in a row by selecting the most appropriate option from the provided list: {', '.join(train_choices[i])}. \\n Given the row: \\n {train_rows[i]} Classify the cell:{train_vals[i]}\"))\n",
    "        messages.append(AIMessage(content=f\"{train_labels[i]}\"))\n",
    "    \n",
    "    #messages.append(SystemMessage(content=\"Your instructions are: 1. Look at the choices given above. 2. Examine the value of the text. 3. Select only ONE of the choices above, that best represents the meaning of this value. 4. Always answer in the format: \\\"selected choice\\\".\"))\n",
    "    messages.append(SystemMessage(content=f\"Your task is to classify a cell entity in a row by selecting the most appropriate option from the provided list: {', '.join(sublist)} \\n Respond only with the choice \" ))\n",
    "    messages.append(HumanMessage(content=f\"Given the row: {test_row} \\n Classify the cell: {key[1]} . Let's think in steps\" ))\n",
    "\n",
    "\n",
    "    if len(messages) >= batch_size:\n",
    "        res = chat(messages)\n",
    "        preds_p5.append(res.content)\n",
    "        messages = []\n",
    "\n",
    "    # Check if the limit is reached\n",
    "    if count >= num_rows_limit:\n",
    "        break\n",
    "\n",
    "if messages:\n",
    "    res = chat(messages)\n",
    "    print(res)  \n",
    "    preds_p5.append(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 6: Chain-of-Thought Zero-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "preds_p6 = []\n",
    "messages = []\n",
    "\n",
    "# Execute prompt messages in batches of 2\n",
    "batch_size = 2\n",
    "\n",
    "# Limit the loop to the first 1000 rows\n",
    "num_rows_limit = 1000\n",
    "count = 0\n",
    "\n",
    "\n",
    "for (key, value),test_row, sublist in tqdm(zip(final_dict.items(),test_rows, entities_text), desc=\"Processing items\", total=len(final_dict)):\n",
    "    count += 1\n",
    "    messages.append(SystemMessage(content=f\"Your task is to classify a cell entity in a row by selecting the most appropriate option from the provided list: {', '.join(sublist)} \\n Respond only with the choice \" ))\n",
    "    messages.append(HumanMessage(content=f\"Given the row: {test_row} \\n Classify the cell: {key[1]} . Let's think in steps\" ))\n",
    "\n",
    "\n",
    "    if len(messages) >= batch_size:\n",
    "        res = chat(messages)\n",
    "        preds_p6.append(res.content)\n",
    "        messages = []\n",
    "\n",
    "    # Check if the limit is reached\n",
    "    if count >= num_rows_limit:\n",
    "        break\n",
    "\n",
    "if messages:\n",
    "    res = chat(messages)\n",
    "    print(res)  \n",
    "    preds_p6.append(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 7: Contrastive Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "preds_p7 = []\n",
    "messages = []\n",
    "\n",
    "# Execute prompt messages in batches of 12\n",
    "batch_size = 12\n",
    "\n",
    "# Limit the loop to the first 1000 rows\n",
    "num_rows_limit = 1000\n",
    "count = 0\n",
    "\n",
    "\n",
    "for (key, value), sublist in tqdm(zip(final_dict.items(), entities_text), desc=\"Processing items\", total=len(final_dict)):\n",
    "    count += 1\n",
    "    for i in range(0,5):\n",
    "        messages.append(HumanMessage(content=f\"Your task is to classify a cell entity in a row by selecting the most appropriate option from the provided list: {', '.join(train_choices_p7_comma[i])}. \\n Classify the cell:{train_vals_p7[i]}\"))\n",
    "        messages.append(AIMessage(content=f\"{train_labels_p7[i]}\"))\n",
    "    \n",
    "    \n",
    "    messages.append(SystemMessage(content=f\"Your task is to classify a cell entity in a row by selecting the most appropriate option from the provided list: {', '.join(sublist)} \\n Respond only with the choice \" ))\n",
    "    messages.append(HumanMessage(content=f\"Classify the cell: {key[1]} . Let's think in steps\" ))\n",
    "\n",
    "\n",
    "    if len(messages) >= batch_size:\n",
    "        res = chat(messages)\n",
    "        preds_p7.append(res.content)\n",
    "        messages = []\n",
    "\n",
    "    # Check if the limit is reached\n",
    "    if count >= num_rows_limit:\n",
    "        break\n",
    "\n",
    "if messages:\n",
    "    res = chat(messages)\n",
    "    print(res)  \n",
    "    preds_p7.append(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pkl files for each prompt prediction\n",
    "from datetime import datetime\n",
    "\n",
    "# Generate a timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "\n",
    "pickle_file_path_p1 = f'../../evaluation/Prediction_Lists/HardTables/HT_prediction_list_p1_{timestamp}_Comma_Row.pkl'\n",
    "with open(pickle_file_path_p1, 'wb') as file:\n",
    "    pickle.dump(preds_p1, file)\n",
    "\n",
    "pickle_file_path_p2 = f'../../evaluation/Prediction_Lists/HardTables/HT_prediction_list_p2_{timestamp}_Comma_Row.pkl'\n",
    "with open(pickle_file_path_p2, 'wb') as file:\n",
    "    pickle.dump(preds_p2, file)\n",
    "\n",
    "\n",
    "pickle_file_path_p3 = f'../../evaluation/Prediction_Lists/HardTables/HT_prediction_list_p3_{timestamp}_Comma_Row.pkl'\n",
    "with open(pickle_file_path_p3, 'wb') as file:\n",
    "    pickle.dump(preds_p3, file)\n",
    "\n",
    "\n",
    "pickle_file_path_p4 = f'../../evaluation/Prediction_Lists/HardTables/HT_prediction_list_p4_{timestamp}_Comma_Row.pkl'\n",
    "with open(pickle_file_path_p4, 'wb') as file:\n",
    "    pickle.dump(preds_p4, file)\n",
    "\n",
    "pickle_file_path_p5 = f'../../evaluation/Prediction_Lists/HardTables/HT_prediction_list_p5_{timestamp}_Comma_Row.pkl'\n",
    "with open(pickle_file_path_p5, 'wb') as file:\n",
    "    pickle.dump(preds_p5, file)\n",
    "\n",
    "pickle_file_path_p6 = f'../../evaluation/Prediction_Lists/HardTables/HT_prediction_list_p6_{timestamp}_Comma_Row.pkl'\n",
    "with open(pickle_file_path_p6, 'wb') as file:\n",
    "    pickle.dump(preds_p6, file)\n",
    "\n",
    "pickle_file_path_p7 = f'../../evaluation/Prediction_Lists/HardTables/HT_prediction_list_p7_{timestamp}_Comma_Row.pkl'\n",
    "with open(pickle_file_path_p7, 'wb') as file:\n",
    "    pickle.dump(preds_p7, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DataFrames of all predictions with their respective links\n",
    "final_df_p1 = functions.final_df_creation(preds_p1, final_dict,letter_pattern='[A-Z]\\.')\n",
    "final_df_p2 = functions.final_df_creation(preds_p2, final_dict,letter_pattern='[A-Z]\\.')\n",
    "final_df_p3 = functions.final_df_creation(preds_p3, final_dict,letter_pattern='[A-Z]\\.')\n",
    "final_df_p4 = functions.final_df_creation(preds_p4, final_dict,letter_pattern='[A-Z]\\.')\n",
    "final_df_p5 = functions.final_df_creation(preds_p5, final_dict,letter_pattern='[A-Z]\\.')\n",
    "final_df_p6 = functions.final_df_creation(preds_p6, final_dict,letter_pattern='[A-Z]\\.')\n",
    "final_df_p7 = functions.final_df_creation(preds_p7, final_dict,letter_pattern='[A-Z]\\.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create CSV Files for the prediction DF\n",
    "functions.prediction_submission_Comma_Cell(final_df_p1,timestamp,\"p1\")\n",
    "functions.prediction_submission_Comma_Cell(final_df_p2,timestamp,\"p2\")\n",
    "functions.prediction_submission_Comma_Cell(final_df_p3,timestamp,\"p3\")\n",
    "functions.prediction_submission_Comma_Cell(final_df_p4,timestamp,\"p4\")\n",
    "functions.prediction_submission_Comma_Cell(final_df_p5,timestamp,\"p5\")\n",
    "functions.prediction_submission_Comma_Cell(final_df_p6,timestamp,\"p6\")\n",
    "functions.prediction_submission_Comma_Cell(final_df_p7,timestamp,\"p7\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
